{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script fetches all CVE records from the NVD API using pagination and stores them in a local `cve_data.json` file.  \n",
    "It handles large data retrieval efficiently by batching requests with a maximum of 2000 records per API call.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE_URL = \"https://services.nvd.nist.gov/rest/json/cves/2.0\"\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "def fetch_cve_batch(start_index=0, results_per_page=2000):\n",
    "    params = {\n",
    "        \"startIndex\": start_index,\n",
    "        \"resultsPerPage\": results_per_page\n",
    "    }\n",
    "    response = requests.get(BASE_URL, headers=HEADERS, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def fetch_all_cves():\n",
    "    all_cves = []\n",
    "    results_per_page = 2000\n",
    "    start_index = 0\n",
    "\n",
    "    # totalResults\n",
    "    print(\"Fetching initial page to get total number of results...\")\n",
    "    initial = fetch_cve_batch(start_index, results_per_page)\n",
    "    if not initial:\n",
    "        return []\n",
    "\n",
    "    total = initial.get(\"totalResults\", 0)\n",
    "    print(f\"Total CVEs: {total}\")\n",
    "\n",
    "    all_cves.extend(initial.get(\"vulnerabilities\", []))\n",
    "    start_index += results_per_page\n",
    "\n",
    "    for i in tqdm(range(start_index, total, results_per_page), desc=\"Fetching pages\"):\n",
    "        # Sleep to avoid rate limiting\n",
    "        time.sleep(1)  \n",
    "        batch = fetch_cve_batch(i, results_per_page)\n",
    "        if batch and \"vulnerabilities\" in batch:\n",
    "            all_cves.extend(batch[\"vulnerabilities\"])\n",
    "        else:\n",
    "            print(f\"Failed to fetch batch at index {i}\")\n",
    "            break\n",
    "\n",
    "    return all_cves\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cve_data = fetch_all_cves()\n",
    "    print(f\"Fetched {len(cve_data)} CVEs.\")\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(\"cve_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cve_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"Saved all CVEs to cve_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b778ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script preprocesses raw CVE data from `cve_data.json`, extracting key fields like ID, scores, and dates while handling missing values.  \n",
    "It also removes duplicate entries based on CVE ID and saves the cleaned result to `nvd_cleaned.json`.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_description(descriptions):\n",
    "    for desc in descriptions:\n",
    "        if desc.get(\"lang\") == \"en\":\n",
    "            return desc.get(\"value\")\n",
    "    return \"No description available\"\n",
    "\n",
    "def extract_score(metrics, version):\n",
    "    try:\n",
    "        key = f\"cvssMetric{version}\"\n",
    "        return metrics[key][0][\"cvssData\"][\"baseScore\"]\n",
    "    except (KeyError, IndexError, TypeError):\n",
    "        return None\n",
    "\n",
    "def preprocess_cve_data(input_path=\"cve_data.json\", output_path=\"nvd_cleaned.json\"):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_data = json.load(f)\n",
    "\n",
    "    cleaned_data = []\n",
    "\n",
    "    for item in raw_data:\n",
    "        cve = item.get(\"cve\", {})\n",
    "        cve_id = cve.get(\"id\")\n",
    "        if not cve_id:\n",
    "            continue  # Skip if ID is missing\n",
    "\n",
    "        published = cve.get(\"published\", \"\")\n",
    "        year = None\n",
    "        try:\n",
    "            year = datetime.fromisoformat(published.replace(\"Z\", \"\")).year\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cleaned_entry = {\n",
    "            \"id\": cve_id,\n",
    "            \"published\": published,\n",
    "            \"lastModified\": cve.get(\"lastModified\"),\n",
    "            \"description\": extract_description(cve.get(\"descriptions\", [])),\n",
    "            \"baseScoreV2\": extract_score(cve.get(\"metrics\", {}), \"V2\"),\n",
    "            \"baseScoreV3\": extract_score(cve.get(\"metrics\", {}), \"V3\"),\n",
    "            \"year\": year,\n",
    "            \"sourceIdentifier\": cve.get(\"sourceIdentifier\", \"\"),\n",
    "            \"vulnStatus\": cve.get(\"vulnStatus\", \"\")\n",
    "        }\n",
    "\n",
    "        cleaned_data.append(cleaned_entry)\n",
    "\n",
    "   # De-duplication based on CVE ID\n",
    "    deduplicated_data = list({entry[\"id\"]: entry for entry in cleaned_data}.values())\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(deduplicated_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Cleaned {len(deduplicated_data)} records and saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_cve_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29dfae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FULL SYNC] Starting full data fetch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching CVEs:   7%|â–‹         | 10/152 [00:34<08:03,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\grpc\\_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    270\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\grpc\\_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[0;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[0;32m    331\u001b[0m )\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\grpc\\_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\grpc\\_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[1;34m(new_details, request)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\grpc\\_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1192\u001b[0m (\n\u001b[0;32m   1193\u001b[0m     state,\n\u001b[0;32m   1194\u001b[0m     call,\n\u001b[0;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1197\u001b[0m )\n\u001b[1;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\grpc\\_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Quota exceeded.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.221.202:443 {created_time:\"2025-08-07T04:32:19.4191144+00:00\", grpc_status:8, grpc_message:\"Quota exceeded.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 Quota exceeded.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INCREMENTAL SYNC] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m updated records uploaded.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 53\u001b[0m     \u001b[43mfull_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# scheduler = BackgroundScheduler()\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# scheduler.add_job(full_sync, 'cron', hour=1)               \u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# scheduler.add_job(incremental_sync, 'interval', hours=2) #Syncs every 2 hours\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# scheduler.start()\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCVE Scheduler started. Press Ctrl+C to stop.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 33\u001b[0m, in \u001b[0;36mfull_sync\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m cleaned \u001b[38;5;241m=\u001b[39m clean_and_deduplicate(raw_data)\n\u001b[0;32m     32\u001b[0m filtered \u001b[38;5;241m=\u001b[39m filter_after_id(cleaned)\n\u001b[1;32m---> 33\u001b[0m \u001b[43mupload_to_firestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[FULL SYNC] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m records uploaded.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m, in \u001b[0;36mupload_to_firestore\u001b[1;34m(cve_list)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m cve_list:\n\u001b[0;32m     24\u001b[0m     doc_id \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcves\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\cloud\\firestore_v1\\document.py:167\u001b[0m, in \u001b[0;36mDocumentReference.set\u001b[1;34m(self, document_data, merge, retry, timeout)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create / replace / merge a document in the Firestore database.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m- To \"upsert\" a document (create if it doesn't exist, replace completely\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    result contains an ``update_time`` field.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m batch, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prep_set(document_data, merge, retry, timeout)\n\u001b[1;32m--> 167\u001b[0m write_results \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _first_write_result(write_results)\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\cloud\\firestore_v1\\batch.py:61\u001b[0m, in \u001b[0;36mWriteBatch.commit\u001b[1;34m(self, retry, timeout)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Commit the changes accumulated in this batch.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    write result contains an ``update_time`` field.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m request, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prep_commit(retry, timeout)\n\u001b[1;32m---> 61\u001b[0m commit_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_firestore_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rpc_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_pbs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_results \u001b[38;5;241m=\u001b[39m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(commit_response\u001b[38;5;241m.\u001b[39mwrite_results)\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\cloud\\firestore_v1\\services\\firestore\\client.py:1431\u001b[0m, in \u001b[0;36mFirestoreClient.commit\u001b[1;34m(self, request, database, writes, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 1431\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    293\u001b[0m )\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:167\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m next_sleep \u001b[38;5;241m=\u001b[39m _retry_error_helper(\n\u001b[0;32m    157\u001b[0m     exc,\n\u001b[0;32m    158\u001b[0m     deadline,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m     timeout,\n\u001b[0;32m    165\u001b[0m )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_sleep\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This modification ensures that only CVEs with IDs greater than or equal to CVE-2006-5072 are uploaded to Firestore, \n",
    "specifically to handle the HTTP 429 \"Quota Exceeded\" error. When the script attempts to fetch and upload a large number of CVEs, \n",
    "it may hit API rate limits, causing a 429 error\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "from datetime import datetime, timedelta\n",
    "from firebase_config import init_firestore\n",
    "from fetch_utils import fetch_all_cves\n",
    "from preprocess_utils import clean_and_deduplicate\n",
    "import time\n",
    "\n",
    "db = init_firestore()\n",
    "\n",
    "START_CVE_ID = \"CVE-2006-5072\"\n",
    "\n",
    "def filter_after_id(cve_list, start_id=START_CVE_ID):\n",
    "    return [cve for cve in cve_list if cve[\"id\"] >= start_id]\n",
    "\n",
    "def upload_to_firestore(cve_list):\n",
    "    for entry in cve_list:\n",
    "        doc_id = entry[\"id\"]\n",
    "        db.collection(\"cves\").document(doc_id).set(entry)\n",
    "        print(f\"Uploaded: {doc_id}\")\n",
    "\n",
    "def full_sync():\n",
    "    print(\"[FULL SYNC] Starting full data fetch...\")\n",
    "    raw_data = fetch_all_cves()\n",
    "    cleaned = clean_and_deduplicate(raw_data)\n",
    "    filtered = filter_after_id(cleaned)\n",
    "    upload_to_firestore(filtered)\n",
    "    print(f\"[FULL SYNC] {len(filtered)} records uploaded.\\n\")\n",
    "\n",
    "def incremental_sync():\n",
    "    print(\"[INCREMENTAL SYNC] Fetching updates from last 24 hours...\")\n",
    "    now = datetime.utcnow()\n",
    "    yesterday = now - timedelta(days=1)\n",
    "\n",
    "    url_params = {\n",
    "        \"lastModStartDate\": yesterday.isoformat() + \"Z\",\n",
    "        \"lastModEndDate\": now.isoformat() + \"Z\"\n",
    "    }\n",
    "\n",
    "    raw_data = fetch_all_cves(url_params=url_params)\n",
    "    cleaned = clean_and_deduplicate(raw_data)\n",
    "    filtered = filter_after_id(cleaned)\n",
    "    upload_to_firestore(filtered)\n",
    "    print(f\"[INCREMENTAL SYNC] {len(filtered)} updated records uploaded.\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    full_sync() \n",
    "    # scheduler = BackgroundScheduler()\n",
    "    # scheduler.add_job(full_sync, 'cron', hour=1)               \n",
    "    # scheduler.add_job(incremental_sync, 'interval', hours=2) #Syncs every 2 hours\n",
    "    # scheduler.start()\n",
    "\n",
    "    print(\"CVE Scheduler started. Press Ctrl+C to stop.\")\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(10)\n",
    "    except KeyboardInterrupt:\n",
    "        # scheduler.shutdown()\n",
    "        print(\"Scheduler stopped.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
